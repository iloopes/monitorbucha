# ğŸ¤– DetecÃ§Ã£o de Anomalias com Autoencoder

Este documento explica como usar o mÃ³dulo de detecÃ§Ã£o de anomalias integrado ao Sistema de ManutenÃ§Ã£o Preditiva.

## ğŸ“‹ VisÃ£o Geral

O **Autoencoder com Janela Deslizante (Moving Window AutoEncoder - MWAE)** detecta anomalias em dados de transformadores em tempo real usando duas mÃ©tricas principais:

- **Q (Erro de ReconstruÃ§Ã£o)**: Mede como bem o modelo consegue reconstruir os dados. Valores altos indicam comportamento anÃ´malo.
- **TÂ² (DistÃ¢ncia no EspaÃ§o Latente)**: Mede a distÃ¢ncia no espaÃ§o comprimido. Valores altos indicam desvios do padrÃ£o normal.

## ğŸ—ï¸ Arquitetura

### Estrutura de Pastas

```
src/anomaly/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ autoencoder.py      # Classes MLPAutoEncoder e CNNAutoEncoder
â””â”€â”€ manager.py          # AnomalyManager para gerenciar treinamento e detecÃ§Ã£o
```

### Componentes

1. **MLPAutoEncoder**: Autoencoder com arquitetura Multi-Layer Perceptron
   - Simples e rÃ¡pido
   - Bom para dados com padrÃµes gerais
   - Menos consumo de memÃ³ria

2. **CNNAutoEncoder**: Autoencoder com arquitetura Convolucional
   - Melhor para sÃ©ries temporais
   - Captura padrÃµes sequenciais
   - Requer mais memÃ³ria

3. **AnomalyManager**: Gerenciador central
   - Treinamento do modelo
   - DetecÃ§Ã£o de anomalias
   - PersistÃªncia em banco de dados

## ğŸš€ Como Usar

### 1. Acessar a Interface Web

1. Navegue atÃ© `http://localhost:3000/anomalies`
2. VocÃª verÃ¡ o dashboard de anomalias com:
   - Resumo de estatÃ­sticas
   - BotÃµes para treinar e detectar
   - Lista de anomalias detectadas

### 2. Treinar o Modelo

```
Clique em "ğŸ¤– Treinar Autoencoder"
```

**ParÃ¢metros padrÃ£o:**
- Model: MLP
- Latent Dim: 5
- Window Size: 168 horas (1 semana)
- Epochs: 50
- Learning Rate: 0.001

O modelo usa dados de `sensor_data` para aprender o padrÃ£o normal de comportamento.

### 3. Detectar Anomalias

```
Clique em "âš¡ Detectar Anomalias"
```

O modelo detectarÃ¡ desvios dos padrÃµes aprendidos e classificarÃ¡ como:
- **CrÃ­tico**: Anomalias severas
- **Alto**: Desvios significativos
- **MÃ©dio**: Comportamento ligeiramente anÃ´malo
- **Baixo**: Comportamento normal

### 4. Visualizar Resultados

#### No Dashboard de Anomalias
- Cards com resumo: total de anomalias, erro mÃ©dio, distÃ¢ncia latente
- Filtros por perÃ­odo: 6h, 12h, 24h, 48h, 168h
- Lista detalhada de cada anomalia detectada

#### No CalendÃ¡rio de ManutenÃ§Ã£o
- Badge vermelha indicando anomalias detectadas
- NÃºmero de anomalias por equipamento
- Resumo geral de anomalias nas Ãºltimas 24h

## ğŸ“Š API Endpoints

### Treinar Modelo
```
POST /api/anomaly/train

Body:
{
  "model_name": "my_model",
  "model_arch": "mlp",        # "mlp" ou "cnn"
  "latent_dim": 5,
  "window_size": 168,
  "num_epochs": 50,
  "learning_rate": 0.001
}
```

### Detectar Anomalias
```
POST /api/anomaly/detect

Body:
{
  "equipment_ids": ["SPGR.ATF1", "SPGR.ATF2"],  # opcional
  "threshold_percentile": 95.0,
  "save_to_database": true
}
```

### Listar Anomalias
```
GET /api/anomaly/list?hours=24&only_anomalies=true

Retorna:
{
  "status": "success",
  "total": 15,
  "anomalies": [...]
}
```

### Resumo de Anomalias
```
GET /api/anomaly/summary?hours=24

Retorna:
{
  "status": "success",
  "summary": {
    "total_points": 100,
    "anomalies_detected": 15,
    "anomaly_percentage": 15.0,
    "mean_Q": 0.0023,
    "mean_T2": 0.0045,
    "max_Q": 0.0156,
    "max_T2": 0.0234
  }
}
```

## ğŸ’¾ Dados no Banco

### Tabela: `anomaly_detections`
```sql
- equipment_id: Identificador do equipamento
- timestamp: Data/hora da detecÃ§Ã£o
- Q: Erro de reconstruÃ§Ã£o
- T2: DistÃ¢ncia no espaÃ§o latente
- Q_threshold: Limiar de Q
- T2_threshold: Limiar de TÂ²
- is_anomaly: Booleano (anomalia detectada?)
- reconstruction_error: Erro de reconstruÃ§Ã£o bruto
- latent_distance: DistÃ¢ncia latente bruta
- severity: 'crÃ­tico', 'alto', 'mÃ©dio', 'baixo'
```

### Tabela: `anomaly_models`
```sql
- model_name: Nome do modelo
- model_arch: Arquitetura ("mlp" ou "cnn")
- latent_dim: DimensÃ£o do espaÃ§o latente
- window_size: Tamanho da janela
- training_epochs: NÃºmero de Ã©pocas
- threshold_percentile: Percentil do threshold
- trained_at: Data do treinamento
```

## ğŸ“ˆ Fluxo Recomendado

```
1. Gerar dados sintÃ©ticos
   â†“
2. Treinar modelo (ğŸ¤– Treinar Autoencoder)
   â†“
3. Executar otimizaÃ§Ã£o (NSGA-II + Markov)
   â†“
4. Detectar anomalias (âš¡ Detectar Anomalias)
   â†“
5. Visualizar calendÃ¡rio com anomalias
   â†“
6. Consultar dashboard de anomalias para detalhes
```

## âš™ï¸ PersonalizaÃ§Ã£o

### Alterar Arquitetura

Para usar CNN em vez de MLP:

```typescript
// Frontend (anomalies/page.tsx)
const response = await api.post('/anomaly/train', {
  model_arch: 'cnn',  // Alterar para 'cnn'
  latent_dim: 5,
  window_size: 168,
  num_epochs: 50
})
```

### Ajustar Threshold

Threshold mais alto = menos anomalias detectadas
```typescript
const response = await api.post('/anomaly/detect', {
  threshold_percentile: 98.0  // Mais restritivo
})
```

### Aumentar Dados de Treinamento

Aumentar `window_size` para usar mais histÃ³rico:
```typescript
window_size: 24 * 30  // 30 dias ao invÃ©s de 7
```

## ğŸ”§ Troubleshooting

### Erro: "Modelo nÃ£o foi treinado"
**SoluÃ§Ã£o**: Clique em "ğŸ¤– Treinar Autoencoder" antes de detectar

### Erro: "Nenhum dado de sensor encontrado"
**SoluÃ§Ã£o**: Gere dados sintÃ©ticos primeiro em "Gerar Dados"

### Poucas anomalias detectadas
**SoluÃ§Ã£o**:
- Reduzir `threshold_percentile` (ex: 90.0)
- Treinar com mais Ã©pocas
- Usar CNN em vez de MLP

### Muitas anomalias (false positives)
**SoluÃ§Ã£o**:
- Aumentar `threshold_percentile` (ex: 98.0)
- Aumentar `window_size` para mais contexto
- Reduzir `num_epochs` para evitar overfitting

## ğŸ“š MÃ©tricas Principais

### Q (Erro de ReconstruÃ§Ã£o)
- **Baixo**: Dados normais, padrÃ£o aprendido corretamente
- **Alto**: Desvio significativo do padrÃ£o normal

### TÂ² (DistÃ¢ncia no EspaÃ§o Latente)
- **Baixo**: Dentro da variÃ¢ncia do padrÃ£o normal
- **Alto**: RepresentaÃ§Ã£o latente anÃ´mala

### Limiar (Threshold)
- Calculado como `percentile(metrica, threshold_percentile)`
- PadrÃ£o: 95Âº percentil (5% dos dados acima)

## ğŸ¯ Casos de Uso

1. **DetecÃ§Ã£o Precoce de Falhas**
   - Identifica padrÃµes anÃ´malos antes que virem falhas
   - Dispara alertas para manutenÃ§Ã£o preventiva

2. **ValidaÃ§Ã£o de Dados**
   - Detecta falhas de sensores
   - Identifica dados corrompidos ou outliers

3. **Monitoramento em Tempo Real**
   - Acompanha mudanÃ§as gradativas
   - Aprende novos padrÃµes normais

4. **AnÃ¡lise HistÃ³rica**
   - Identifica perÃ­odos de operaÃ§Ã£o anÃ´mala
   - Correlaciona com eventos de manutenÃ§Ã£o

## ğŸ”— IntegraÃ§Ã£o com CalendÃ¡rio

O calendÃ¡rio de manutenÃ§Ã£o agora mostra:

1. **Badge de Anomalias**: "ğŸš¨ 2 anomalia(s)" prÃ³ximo ao nome do equipamento
2. **Resumo de Anomalias**: Card com estatÃ­sticas gerais
3. **Filtros Temporais**: AnÃ¡lise de diferentes perÃ­odos

Exemplo de card no calendÃ¡rio:
```
SPGR.ATF1 [ğŸš¨ 3 anomalia(s)]
SPGR - Substation Guarulhos
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… Data: Quinta-feira, 26 de novembro de 2025
â±ï¸ Dias: 15 dias
ğŸ”§ Estado: 2
ğŸ’° Custo: R$ 5000.00
âš ï¸ Prioridade: 4
ğŸ“Š Indisponibilidade: 2.5000
```

## ğŸ“¦ DependÃªncias

As seguintes bibliotecas sÃ£o usadas:
- `torch`: Deep learning
- `scikit-learn`: NormalizaÃ§Ã£o de dados
- `pandas`: ManipulaÃ§Ã£o de dados
- `numpy`: OperaÃ§Ãµes numÃ©ricas
- `pyodbc`: ConexÃ£o com SQL Server

```bash
pip install torch scikit-learn pandas numpy pyodbc
```

## ğŸ“ ReferÃªncias TeÃ³ricas

### Autoencoder
Um autoencoder Ã© uma rede neural que comprime (encoda) dados em um espaÃ§o latente menor e depois reconstrÃ³i (decoda) os dados originais. Na detecÃ§Ã£o de anomalias:

- Dados normais sÃ£o bem reconstruÃ­dos
- Dados anÃ´malos tÃªm alto erro de reconstruÃ§Ã£o

### Janela Deslizante (Moving Window)
Processa dados em janelas temporais sequenciais, permitindo:

- Captura de padrÃµes sequenciais
- DetecÃ§Ã£o de anomalias em sÃ©ries temporais
- AnÃ¡lise de mudanÃ§as gradativas

### NSGA-II + Autoencoder
CombinaÃ§Ã£o poderosa:

- **NSGA-II**: Otimiza quando fazer manutenÃ§Ã£o
- **Autoencoder**: Detecta quando hÃ¡ problema

Fluxo: Anomalia â†’ Disparar otimizaÃ§Ã£o â†’ Agendar manutenÃ§Ã£o

## ğŸ’¡ Dicas e Boas PrÃ¡ticas

1. **Treinar regularmente**: Retreine o modelo a cada novo ciclo de dados
2. **Monitorar mÃ©tricas**: Acompanhe Q e TÂ² para mudanÃ§as de padrÃ£o
3. **Validar alertas**: Verifique false positives e ajuste thresholds
4. **Manter histÃ³rico**: Armazene dados de treino para anÃ¡lises futuras
5. **Combinar mÃ©todos**: Use anomalias + otimizaÃ§Ã£o + calendÃ¡rio para mÃ¡xima eficÃ¡cia

---

**VersÃ£o**: 1.0
**Ãšltima atualizaÃ§Ã£o**: 2025-11-26
**Autor**: Sistema de ManutenÃ§Ã£o Preditiva 2.0
